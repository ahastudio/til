# Codex App Server

OpenAI의 코딩 에이전트 Codex는 웹 앱, CLI, IDE 확장, macOS 데스크톱 앱
등 다양한 표면(surface)에서 동작한다. 이 모든 표면의 공통 기반이 되는 것이
**Codex 하니스(harness)** — 에이전트 루프와 핵심 로직 — 이며, App Server는
이 하니스를 클라이언트에 노출하는 **양방향 JSON-RPC API**다.

<https://developers.openai.com/codex/app-server/>

Unlocking the Codex harness: how we built the App Server:
<https://openai.com/index/unlocking-the-codex-harness/>

## 아키텍처

모든 에이전트 로직은 **Codex core**라는 Rust 기반 라이브러리 겸
런타임에 존재한다. Codex core는 에이전트 루프를 실행하고 하나의
Codex 스레드(대화)의 영속성을 관리한다.

App Server 프로세스는 네 가지 핵심 구성 요소로 이루어진다.

1. **stdio reader** — 클라이언트의 JSON-RPC 요청을 읽는다
2. **Codex message processor** — 요청을 Codex core 연산으로 변환하고,
   core의 내부 이벤트 스트림을 수신하여 UI에 적합한 JSON-RPC
   알림으로 변환한다
3. **thread manager** — 각 스레드마다 하나의 core 세션을 생성하고
   관리한다
4. **core threads** — 개별 에이전트 세션의 컨테이너

## 프로토콜: JSON-RPC lite

"JSON-RPC lite"라는 변형을 사용한다. JSON-RPC 2.0의
요청/응답/알림 형태는 유지하되, `"jsonrpc": "2.0"` 헤더를 생략하고
**JSONL over stdio**로 프레이밍한다.

전송 모드는 두 가지다.

- **stdio (기본)** — `codex app-server --listen stdio://`
- **WebSocket (실험적)** — `--listen ws://IP:PORT`

호스팅 환경에서는 stdio 스트림이 WebSocket과 유사한 지속적 네트워크
연결을 통해 터널링되므로, 실제 로컬 파이프가 아니더라도 stdio처럼
동작한다.

## 대화 프리미티브

세 가지 대화 프리미티브로 설계되어 있다.

### Item

입력 또는 출력의 **원자적 단위**. 명시적 생명주기를 갖는다.

- `item/started` — 시작
- `item/agentMessage/delta` — 스트리밍 델타 (선택적)
- `item/completed` — 완료

Item의 종류: 사용자 메시지, 에이전트 메시지, 도구 실행,
승인 요청, diff.

### Turn

하나의 사용자 입력에 의해 시작되는 **에이전트 작업 단위**.
순서가 있는 Item들의 시퀀스를 그룹화한다.

- `turn/start` — 턴 시작 (threadId, 사용자 입력 포함)
- `turn/steer` — 진행 중인 턴에 추가 입력 삽입
- `turn/completed` — 턴 완료

### Thread

진행 중인 세션의 **내구적 컨테이너**. JSONL 파일로 디스크에
영속화된다.

- `thread/start` — 새 대화 시작
- `thread/resume` — 기존 대화 재개
- `thread/fork` — 히스토리를 새 thread id로 분기
- `thread/rollback` — 마지막 N개의 턴을 롤백
- `thread/archive` — 아카이브 디렉토리로 이동

## 양방향 통신

일반적인 스레드에서는 클라이언트 요청 하나에 서버 알림이 여러 개
따라온다. 그러나 프로토콜은 **서버 주도 요청**도 지원한다.

에이전트가 명령 실행 전 승인이 필요할 때, 서버가 클라이언트에 요청을
보내고 "allow" 또는 "deny" 응답을 받을 때까지 턴을 일시 중지한다.

## 클라이언트 통합 모델

세 가지 통합 패턴이 존재한다.

**로컬/IDE 클라이언트** — VS Code 확장이나 데스크톱 앱은
플랫폼별 바이너리를 번들하거나 가져와서, 장기 실행 자식 프로세스로
시작하고 양방향 stdio 채널을 유지한다.

**웹 런타임** — 워커가 컨테이너를 프로비저닝하고 그 안에서
App Server 바이너리를 실행한다. 브라우저는 HTTP와 SSE(Server-Sent
Events)를 통해 Codex 백엔드와 통신한다. 브라우저 측 UI를 가볍게
유지하면서도 데스크톱과 일관된 런타임을 제공한다.

**파트너 통합** — JetBrains, Xcode 등 파트너는 클라이언트를
안정적으로 유지하면서 새로운 App Server 바이너리를 가리키는 방식으로
릴리스 주기를 분리한다.

클라이언트 바인딩은 Go, Python, TypeScript, Swift, Kotlin으로
구현되어 있으며, 스키마 생성 도구도 제공한다.

```bash
codex app-server generate-ts
codex app-server generate-json-schema
```

## 인증

세 가지 인증 모드를 지원한다.

- **API key** — 호출자가 OpenAI API 키를 직접 제공
- **ChatGPT managed** — Codex가 OAuth 플로우를 관리하고 토큰을
  자동 갱신
- **ChatGPT external tokens** — 호스트 앱이 `idToken`과
  `accessToken`을 직접 공급

## MCP를 시도하고 버린 이유

VS Code 확장을 만들 때 처음에는 Codex를 **MCP 서버**로 노출하는
실험을 했다. 그러나 IDE 상호작용에 필요한 풍부한 세션 시맨틱 —
스트리밍 diff, 승인 플로우, 스레드 영속성 — 이 MCP의 도구 지향
모델에 깔끔하게 매핑되지 않았다.

OpenAI는 단순한 워크플로우에는 여전히 MCP 서버를 지원하지만,
완전한 통합에는 App Server를 권장한다.

## 진화 과정

1. Codex CLI가 TUI(터미널 사용자 인터페이스)로 시작
2. VS Code 확장 개발 시, 같은 하니스를 IDE UI에서 구동할 방법이
   필요해짐
3. MCP 서버 실험 → 실패
4. TUI 루프를 미러링하는 JSON-RPC 프로토콜 도입
5. 내부 팀과 외부 파트너(JetBrains, Xcode, 데스크톱 앱)의 수요가
   늘면서 범용 플랫폼 표면으로 발전

## 인사이트

### 프로토콜이 제품을 통일한다

Codex의 핵심 교훈은 **에이전트 로직과 표면(UI)의 분리**다. CLI,
IDE 확장, 웹 앱, 데스크톱 앱이라는 네 가지 제품이 하나의 프로토콜
위에서 동작한다.

이것이 가능한 이유는 프로토콜이 단순한 API가 아니라 **에이전트
대화의 구조적 모델**이기 때문이다. Item, Turn, Thread라는 세 가지
프리미티브가 에이전트의 행동 패턴 — 스트리밍 출력, 도구 실행,
승인 요청, 세션 지속 — 을 정확하게 포착한다.

이 설계가 없었다면 네 개의 제품은 네 개의 에이전트 구현이 되었을
것이다. 프로토콜 하나가 코드 중복, 동작 불일치, 유지보수 비용을
동시에 해결한다.

### 실용이 표준을 이긴다

MCP(Model Context Protocol)는 AI 도구 통합의 사실상 표준으로
자리잡아가고 있다. OpenAI가 MCP를 시도한 것은 자연스러운
선택이었다. 그러나 **실제 제품의 요구사항** 앞에서 표준은
후퇴했다.

MCP의 한계는 도구 호출 중심의 단순한 모델이라는 점이다.
에이전트가 코드를 수정하고, diff를 스트리밍하고, 사용자 승인을
기다리고, 세션을 영속화하는 복잡한 상호작용은 MCP의 설계
의도를 넘어선다.

여기서 얻는 교훈: 표준의 채택은 목표가 아니라 **수단**이다.
제품이 표준에 맞지 않을 때, 표준을 억지로 따르는 것보다 제품에
맞는 프로토콜을 만드는 것이 올바른 판단이다. OpenAI는 MCP를
버리지 않았다 — 단순한 워크플로우에는 여전히 지원한다. 맥락에
따라 적절한 도구를 선택한 것이다.

### stdio가 보편적 전송 계층이 된 이유

App Server의 기본 전송은 stdio다. 가장 원시적인 프로세스 간
통신 방식이 왜 2026년의 AI 에이전트 프로토콜에 채택되었는가?

첫째, **언어 독립성**이다. Go, Python, TypeScript, Swift,
Kotlin — 어떤 언어든 stdin/stdout을 읽고 쓸 수 있다. 특정
라이브러리나 프레임워크에 의존하지 않는다.

둘째, **배포 유연성**이다. 로컬에서는 자식 프로세스의 stdio
파이프를 직접 사용하고, 호스팅 환경에서는 WebSocket이나 SSE로
터널링한다. 전송 계층이 바뀌어도 프로토콜은 동일하다.

셋째, **디버깅 용이성**이다. JSONL은 사람이 읽을 수 있는
텍스트다. 파이프를 tap하면 에이전트와 클라이언트 사이의 모든
통신을 그대로 볼 수 있다.

가장 단순한 인터페이스가 가장 넓은 호환성을 제공한다.
Unix 철학의 핵심이 AI 에이전트 시대에도 유효함을 보여준다.

### 서버가 클라이언트에 요청하는 역전

전통적인 클라이언트-서버 모델에서 요청은 항상 클라이언트에서
서버로 흐른다. App Server는 이 방향을 **역전**시킨다. 에이전트가
명령을 실행하기 전에 서버가 클라이언트에 승인을 요청하고, 응답을
받을 때까지 턴을 일시 중지한다.

이것은 단순한 기술적 선택이 아니라 **에이전트 안전성의 구조적
보장**이다. 에이전트가 자율적으로 행동하되, 위험한 작업에서는
인간이 개입할 수 있는 지점을 프로토콜 수준에서 강제한다.

Human-in-the-loop를 애플리케이션 로직이 아닌 **통신 프로토콜에
내장**한 것이다. 이로써 어떤 클라이언트가 App Server에 연결하든
동일한 안전성 보장을 받는다.

### Thread의 내구성이 웹의 취약성을 극복한다

웹 세션은 본질적으로 취약하다. 탭이 닫히고, 네트워크가
끊기고, 브라우저가 충돌한다. 그러나 에이전트의 작업은 수십 분에서
수시간이 걸릴 수 있다.

App Server는 Thread를 JSONL 파일로 디스크에 영속화함으로써 이
문제를 해결한다. 상태와 진행 상황을 서버에 유지하므로, 탭이
사라져도 작업은 계속된다. 새 세션이 연결되면 Thread를 resume하여
상태를 재구축할 수 있다.

fork와 rollback은 여기서 한 발 더 나아간다. fork는 대화의
**분기점을 만드는 Git branch**다. rollback은 마지막 N개 턴을
되돌리는 **Git revert**다. 에이전트와의 대화에 버전 관리의
개념을 도입한 것이다.

### 점진적 진화의 힘

App Server는 처음부터 범용 프로토콜로 설계되지 않았다.
CLI의 TUI를 VS Code에서 재사용하려는 **실용적 필요**에서
출발했다. 그것이 점차 JetBrains, Xcode, 웹 앱, 데스크톱 앱으로
확장되면서 범용 플랫폼이 되었다.

이것은 소프트웨어 설계의 중요한 패턴이다. 처음부터 완벽한
프로토콜을 설계하려 하면 과도한 추상화와 사용되지 않는 기능이
생긴다. 실제 제품의 요구사항에 대응하며 점진적으로 확장하면
**필요한 것만 정확하게** 갖춘 프로토콜이 만들어진다.

MCP를 시도하고 버린 것도, WebSocket을 실험적으로 추가한 것도,
이 점진적 진화의 일부다. 실패를 허용하고 방향을 수정하는
과정에서 올바른 설계가 드러난다.

### 에이전트 시대의 아키텍처 패턴

App Server 아키텍처는 앞으로 AI 에이전트 제품을 구축하는
팀들에게 하나의 **참조 모델**이 될 수 있다.

핵심 패턴은 명확하다.

- 에이전트 로직을 하나의 core에 집중시킨다
- 양방향 프로토콜로 다양한 표면을 지원한다
- 대화를 구조적 프리미티브(Item, Turn, Thread)로 모델링한다
- 승인 플로우를 프로토콜에 내장한다
- 세션을 영속화하여 연결 끊김에 대응한다

이 패턴은 Codex에 특화된 것이 아니다. 코드 에이전트든, 데이터
분석 에이전트든, 고객 지원 에이전트든 — **장기 실행되는 자율적
작업을 수행하면서 인간의 감독이 필요한** 모든 에이전트 시스템에
적용 가능한 아키텍처다.

