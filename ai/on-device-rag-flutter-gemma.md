# 온디바이스 RAG: 임베딩, 벡터 검색, 그리고 그 너머

원문:
<https://medium.com/google-developer-experts/47127e954c24>

저자: Sasha Denisov (Google Developer Expert)
날짜: 2026-02-21

## 요약

오프라인 AI 에이전트에게 "기억"을 부여하는 방법을
다룬다.
사용자의 개인 데이터를 검색하고 활용하는
RAG(Retrieval-Augmented Generation) 파이프라인을
Flutter Gemma로 온디바이스에서 구현하는
전체 과정을 설명한다.

핵심 주장은 세 가지다.
첫째, LLM에 데이터를 전부 넣거나 파인튜닝하는
것보다 쿼리 시점에 관련 데이터만 검색하는
RAG가 낫다.
둘째, 임베딩 생성부터 벡터 검색, 응답 생성까지
모든 파이프라인을 클라우드 없이 디바이스에서
실행할 수 있다.
셋째, 시맨틱 검색만으로는 날짜·필터·정렬 같은
구조화된 쿼리를 처리할 수 없으므로
Function Calling을 결합한 에이전틱 RAG가
필요하다.

## LLM에 개인 데이터를 제공하는 세 가지 접근

CRM 앱을 예시로 든다.
"지난주 미팅에서 팔로업할 사람은?"이라는 질문에
LLM이 답하려면 연락처, 대화 이력, 비즈니스 맥락
등 개인 데이터에 접근해야 한다.

| 접근법              | 방식            | 한계                       |
| ------------------- | --------------- | -------------------------- |
| A. 프롬프트에 전부  | 컨텍스트에 덤프 | 토큰 한도, 느림, 중간 망각 |
| B. 파인튜닝         | 모델 재훈련     | 데이터 변경 시 재훈련 필요 |
| C. RAG (승자)       | 쿼리 시 검색    | 항상 최신, 사용자별 확장   |

프롬프트에 500개 연락처를 전부 넣으면
토큰 한도를 초과한다.
파인튜닝은 매일 변하는 CRM 데이터에 맞지 않는다.
RAG는 질문과 관련된 연락처만 검색해서 LLM에
전달하므로 세 문제를 모두 해결한다.

## 시맨틱 검색과 임베딩

키워드 검색은 "big company"로
"enterprise client"를 찾지 못한다.
시맨틱 검색은 텍스트를 벡터로 변환해
의미적 유사성을 수학적으로 계산한다.

임베딩 모델이 텍스트를 768차원 벡터로 변환한다:

```
"enterprise sales lead"  → [0.12, -0.45, 0.78, ...]
"big company executive"  → [0.11, -0.44, 0.77, ...]  (유사!)
"banana smoothie recipe" → [0.89, 0.12, -0.34, ...]  (다름)
```

### 온디바이스 임베딩 모델

| 모델           | 파라미터 | 기반      | 특징                |
| -------------- | -------- | --------- | ------------------- |
| EmbeddingGemma | 308M     | Gemma 3   | 정확도 우선         |
| Gecko          | 110M     | 지식 증류 | 2.6배 빠름, 정확도↓ |

Google이 2025년 9월 출시한 EmbeddingGemma는
온디바이스용으로 설계됐다.
Flutter Gemma에서 Android는 AI Edge LocalAgents
RAG SDK를 사용하고, iOS와 Web은
TFLite 인터프리터와 LiteRT.js로 직접 구현했다.

## 벡터 저장과 검색

### 플랫폼별 SQLite 구현

| 플랫폼  | 구현 방식                 | 비고                 |
| ------- | ------------------------- | -------------------- |
| Android | `SQLiteOpenHelper` + BLOB | float32, 벡터당 3KB  |
| iOS     | SQLite3 C API + BLOB      | Android와 바이너리 호환 |
| Web     | wa-sqlite + OPFS          | Web Worker 필수      |

세 플랫폼 모두 동일한 스키마, BLOB 인코딩,
코사인 유사도 계산을 사용한다.
클라우드 벡터 DB(Pinecone, Chroma, Qdrant) 대신
모든 플랫폼에 내장된 SQLite를 선택했다.
ObjectBox도 대안이지만, 추가 의존성 없는 SQLite를
기본으로 제공한다.

### HNSW 알고리즘

브루트포스 검색은 O(n)이다.
10만 건이면 10만 번 유사도를 계산해야 한다.

HNSW(Hierarchical Navigable Small World)는
다층 그래프 구조로 O(log n)에 검색한다.
지하철 노선에 비유하면, 상위 레이어는 급행 노선이고
하위 레이어는 완행 노선이다.
검색은 상위에서 큰 점프로 근처까지 이동한 뒤,
하위에서 정밀 탐색한다.
10만 건에서 약 17번 비교로 결과를 찾는다.

Flutter Gemma는 "과다 인출 후 재순위" 전략을
쓴다.
HNSW로 후보를 2배 가져온 뒤,
정확한 코사인 유사도로 상위 K개를 필터링한다.

## 데이터 수집과 검색 흐름

### 데이터 수집

```
최초 로드 → 전체 레코드 벡터화 → 저장
데이터 변경 감지 → 개별 레코드 갱신 (INSERT OR REPLACE)
```

핵심: 벡터 저장소는 기본 데이터의 파생 캐시다.
동기화가 어긋나면 검색 결과가 부정확해진다.

### 검색

```
사용자 질문 → 벡터 변환 → 유사 문서 검색 (top-K)
→ 컨텍스트 구성 → LLM에 전달 → 응답 생성
```

코사인 유사도로 가장 가까운 벡터를 찾는다.
점수는 -1에서 1 사이이며,
0.3~0.4 이상이면 보통 관련성이 있다.

### 청킹

벡터화 전에 데이터를 검색 단위로 나눠야 한다.
CRM 데이터는 "연락처 1건 = 문서 1건"으로
자연스럽게 나뉘지만,
미팅 노트나 이메일은 전략이 필요하다.

- 고정 크기 분할: 단순하지만 문장이 잘릴 수 있다.
- 의미 단위 분할: 의미 경계를 존중한다.
- 문서 구조 분할: 문단, 섹션 단위.
- 10~20% 오버랩을 권장한다.

## 시맨틱 검색의 한계

"Find my enterprise contacts"는 잘 동작한다.
"Fortune 500", "big deal", "Alphabet" 같은
레코드를 의미적으로 연결해서 찾아준다.

하지만 다음 질문들은 실패한다:

| 질문 유형   | 예시                        | 실패 이유      |
| ----------- | --------------------------- | -------------- |
| 시간 기반   | "어제 누구와 통화했나?"     | 날짜 추론 불가 |
| 구조화 필터 | "이메일 없는 리드"          | 필드 필터 불가 |
| 정렬        | "가장 오래 연락 안 한 사람" | 정렬 불가      |
| 집계        | "회사별 연락처 수"          | 집계 불가      |

"어제"라는 단어의 임베딩은 "최근", "과거"와
유사하지만 "2026-01-19"와는 벡터 공간에서
가깝지 않다.
이런 쿼리에는 추론이 필요하다.

## 에이전틱 RAG: Function Calling 결합

시맨틱 검색의 한계를 극복하기 위해
LLM이 의도를 파악하고 함수를 호출하는
에이전틱 RAG 패턴을 쓴다.
저자는 이것을 2025-2026 지배 패턴이라 부른다.

Google의 FunctionGemma(270M 파라미터)가
사용자 의도를 파싱해서 적절한 파라미터로
함수를 호출한다.

### 하이브리드 검색 흐름

```
사용자 질문
  → FunctionGemma가 의도 파싱
      → 시맨틱 쿼리: RAG로 처리
      → 구조화 필터: SQL/필터로 처리
  → 결과 통합
  → LLM이 응답 생성
```

예시:

```
"Google 연락처 중 엔터프라이즈 가격에 관심 있는 사람"
→ company="Google"
→ semantic_query="interested in enterprise pricing"
→ 시맨틱 검색 + 회사 필터 결합
```

LLM은 언어 이해와 날짜 추론을 담당하고,
구조화된 쿼리는 필터링, 정렬, 조인을 담당한다.

## 기술 스택 요약

| 구성 요소      | 도구/모델             | 역할                 |
| -------------- | --------------------- | -------------------- |
| 임베딩 생성    | EmbeddingGemma (308M) | 텍스트 → 벡터 변환   |
| 빠른 임베딩    | Gecko (110M)          | 경량 임베딩 대안     |
| 벡터 저장/검색 | SQLite + HNSW         | 온디바이스 벡터 DB   |
| 의도 파싱      | FunctionGemma (270M)  | 자연어 → 구조화 쿼리 |
| 응답 생성      | Gemma (온디바이스)    | 컨텍스트 기반 생성   |
| 프레임워크     | Flutter Gemma         | 크로스 플랫폼 통합   |

## 인사이트

### 1) 온디바이스 RAG의 진짜 가치는 프라이버시다

클라우드 RAG와 기능적으로 동일하지만,
데이터가 디바이스를 떠나지 않는다는 점이
본질적 차별점이다.
CRM, 의료, 법률 등 민감한 데이터를 다루는
앱에서 "오프라인으로 동작한다"는 것은
기능이 아니라 규제 준수 요건이다.
GDPR, HIPAA 같은 규정 하에서 클라우드 RAG는
데이터 처리 동의와 암호화 등 추가 부담이 크다.
온디바이스 RAG는 이 부담을 구조적으로 제거한다.

### 2) 308M 파라미터로 충분한 임베딩이 가능하다

생성 모델이 수십억 파라미터를 요구하는 것과 달리
임베딩 모델은 훨씬 작은 크기로 실용적 품질을
달성한다.
이것은 RAG 파이프라인에서 임베딩 생성이
가장 먼저 모바일에서 실현 가능한 단계였다는
뜻이다.
검색은 가볍게, 생성만 무겁게 처리하는
아키텍처가 자연스럽게 나온다.

### 3) 에이전틱 RAG가 표준 패턴이 되고 있다

단순 시맨틱 검색에서 Function Calling 결합으로의
진화 경로는 서버 사이드 RAG에서도 동일하게
관찰되는 흐름이다.
LLM이 "검색 오케스트레이터" 역할을 하면서
어떤 검색 방법을 쓸지, 어떤 필터를 적용할지를
스스로 결정하는 패턴이 표준이 되고 있다.
이 글은 이 패턴을 온디바이스에서
270M 모델로도 구현할 수 있음을 보여준다.

### 4) SQLite가 벡터 DB를 대체할 수 있다

Pinecone, Chroma, Qdrant 같은 전용 벡터 DB
대신 모든 플랫폼에 내장된 SQLite로
벡터 검색을 구현했다.
HNSW 인덱싱을 직접 구현하는 비용이 있지만,
추가 의존성 없이 크로스 플랫폼 지원이 가능하다.
모바일 앱에서 데이터 규모가 수십만 건 이하라면
전용 벡터 DB의 이점이 크지 않다는 실용적 판단이다.

### 5) 청킹 전략이 검색 품질을 좌우한다

임베딩 모델과 벡터 DB가 아무리 좋아도
데이터를 어떻게 쪼개느냐가 검색 품질을 결정한다.
CRM은 자연스럽게 나뉘지만,
미팅 노트나 이메일은 전략이 필요하다.
10~20% 오버랩 권장은 청크 경계에서
컨텍스트가 유실되는 문제를 방지하기 위함이다.
이것은 Chunk Translator가 요약 컨텍스트로
청크 간 일관성을 유지하는 것과 같은 문제를
다른 방식으로 해결하는 것이다.

## 적용 아이디어

- 개인 지식 관리 앱에서 노트, 북마크, 메모를
  시맨틱 검색하는 오프라인 AI 비서.
- 사내 연락처나 문서를 디바이스에서만 검색하는
  프라이버시 우선 CRM.
- 헬스케어 앱에서 환자 데이터를 클라우드에
  올리지 않고도 AI 기반 검색과 요약.
- EmbeddingGemma + FunctionGemma 조합으로
  578M 파라미터만으로 에이전틱 RAG 전체
  파이프라인을 모바일에서 실행.
- 기존 SQLite 기반 앱에 HNSW 인덱싱만
  추가하면 별도 벡터 DB 없이 시맨틱 검색 도입.

## 관련 문서

- [RAG (Retrieval-Augmented Generation)](../llm/rag.md)
- [Chunk Translator 분석](chunk-translator.md)
