# GLM-5 - Z.AI의 차세대 프론티어 모델

<https://z.ai/blog/glm-5>

Zhipu AI(Z.AI)가 2026년 2월 11일 공개한 5세대 대규모 언어 모델.
칭화대 스핀오프인 Zhipu AI는 2025년 Z.AI로 리브랜딩했고,
2026년 1월 8일 홍콩 IPO를 통해 HKD 43.5억(약 $5.58억)을
조달하며 세계 최초 상장 파운데이션 모델 기업이 되었다.

## 아키텍처

- **파라미터**: 총 744B, 활성 파라미터 40B
- **구조**: Mixture of Experts(MoE),
  256개 전문가 중 토큰당 8개 활성화(약 5.9% 희소성)
- **컨텍스트**: 입력 200K 토큰, 출력 최대 128K 토큰
- **사전학습 데이터**: 28.5T 토큰(GLM-4.5의 23T에서 증가)
- **학습 하드웨어**: Huawei Ascend 910B 10만 장,
  MindSpore 프레임워크 사용.
  미국산 반도체 없이 학습을 완료한 점이 주목할 만하다.
- **DeepSeek Sparse Attention(DSA)** 통합으로
  배포 비용을 줄이면서 긴 컨텍스트 처리 능력을 유지한다.

## 벤치마크

| 벤치마크              | GLM-5 | 비교 모델              |
| --------------------- | ----- | ---------------------- |
| SWE-bench Verified    | 77.8  | Claude Opus 4.5: 80.9 |
| AIME 2026             | 92.7  |                        |
| GPQA-Diamond          | 86.0  |                        |
| Humanity's Last Exam  | 50.4  | Claude Opus 4.5 상회   |
| BrowseComp            | 75.9  | 오픈소스 1위           |
| Terminal-Bench 2.0    | 56.2  |                        |

오픈소스 모델 중 추론, 코딩, 에이전트 벤치마크 전반에서
1위를 기록했다. OpenAI GPT-5.2, Anthropic Claude Opus 4.5와
경쟁 가능한 수준이다.

### 환각률

Artificial Analysis 기준 환각률을 GLM-4.7의 90%에서 34%로
압축했다. 전작 대비 35포인트 개선으로 업계 최저 수준이다.

## Slime - 비동기 RL 프레임워크

<https://github.com/THUDM/slime>

GLM-5의 사후학습(post-training)에 사용된 강화학습
프레임워크다. 기존 RL 학습은 추론-평가-업데이트를
순차적으로 실행하여 전체 학습 시간의 90% 이상이 대기
시간이었다.

### 핵심 구조

Slime는 세 가지 비동기 모듈로 구성된다.

1. **학습 모듈**: Megatron-LM 기반 대규모 최적화
2. **롤아웃 모듈**: SGLang과 커스텀 라우터로
   고처리량 데이터 생성
3. **데이터 버퍼**: 프롬프트 초기화와 롤아웃 저장을
   담당하는 중앙 허브

이 세 단계를 독립적인 비동기 파이프라인으로 분리하여
추론, 평가, 파라미터 업데이트를 병렬 실행한다.

### APRIL (Active Partial Rollouts)

롤아웃 생성 단계의 긴 꼬리(long-tail) 병목을 해소하는
시스템 수준 최적화 기법이다. 요청을 의도적으로 과다
배치(over-provision)하고 부분 완료를 능동적으로 관리하여
RL 학습 시간의 90% 이상을 차지하던 롤아웃 대기를 줄인다.

### 학습 규모

사후학습 한 번에 3,000~6,000개 메시지(약 6,000만~1억 출력
토큰)를 생성하며 장기 계획 수립과 도구 사용을 정교화한다.
적응형 검증 환경과 다중 턴 컴파일 피드백 루프도 지원한다.

## 다섯 가지 핵심 역량

1. **창작(Creative Writing)**: 문서, 보고서 등 전문 콘텐츠
2. **코딩(Coding)**: SWE-bench 77.8로 프론티어 모델에 근접
3. **고급 추론(Advanced Reasoning)**: AIME 92.7, GPQA 86.0
4. **에이전트 지능(Agentic Intelligence)**: 고수준 목표를
   하위 작업으로 분해하고 자율 실행하는 Agent Mode 내장
5. **긴 컨텍스트(Long Context)**: 200K 컨텍스트 윈도우

## "바이브 코딩에서 에이전트 엔지니어링으로"

Z.AI는 GLM-5가 "바이브 코딩(vibe coding)"에서
"에이전트 엔지니어링(agentic engineering)"으로의 전환을
대표한다고 설명한다. AI가 단순히 코드를 생성하는 수준을
넘어 대규모 자동화 코딩을 수행하는 방향이다.

## Pony Alpha

정식 공개 전 2026년 2월 초 OpenRouter에 "Pony Alpha"라는
이름으로 스텔스 출시되었다. 첫날 400억 토큰을 처리했다.
2026년이 말의 해인 점을 눈치챈 사람도 있었다.

## 가격 및 이용

| 항목       | 내용                           |
| ---------- | ------------------------------ |
| 입력 토큰  | ~$0.80~1.00 / 1M 토큰         |
| 출력 토큰  | ~$2.56~3.20 / 1M 토큰         |
| 라이선스   | MIT (오픈 웨이트)              |
| 플랫폼     | chat.z.ai, OpenRouter          |
| 모델 가중치| HuggingFace (zai-org/GLM-5)    |
| 변형       | GLM-5 (BF16), GLM-5-FP8 (FP8) |
| 배포 지원  | vLLM, SGLang, xLLM             |

## 인사이트

**오픈소스 프론티어의 현실화**.
GLM-5는 오픈 웨이트 모델이 클로즈드 프론티어 모델과
경쟁 가능함을 보여주는 실제 사례다. MIT 라이선스로
상업적 사용과 파인튜닝이 자유롭다.

**하드웨어 독립성의 증명**.
Huawei Ascend 칩만으로 프론티어급 모델 학습을
완료했다는 것은 미국 수출 규제 하에서도 대안적 컴퓨팅
스택이 작동함을 입증한다.

**RL 스케일링의 새로운 접근**.
Slime 프레임워크의 비동기 RL 아키텍처는 사후학습의
효율성 문제에 대한 구체적인 해법을 제시한다.
APRIL 기법으로 긴 꼬리 병목을 해소한 점도 실용적이다.

**에이전트 지능 중심 설계**.
단순 벤치마크 점수보다 실제 에이전트 작업(Vending Bench,
BrowseComp 등)에서의 성능을 강조하는 방향은 LLM 평가
기준의 변화를 반영한다.

**공격적 가격 전략**.
GPT-4 대비 약 21배 저렴한 가격은 프론티어 모델의
접근성을 크게 낮춘다. 상장 기업으로서 지속 가능한
가격인지는 지켜볼 필요가 있다.
