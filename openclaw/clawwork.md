# ClawWork

OpenClaw 생태계를 "도구"에서 "AI 동료" 관점으로 확장한 실험 프레임워크.

- 프로젝트: <https://github.com/HKUDS/ClawWork>
- 공개: 2026-02-16 (HKUDS)
- 핵심 질문: "이 에이전트가 스스로 돈을 벌며 생존할 수 있는가?"

## 한 줄 요약

ClawWork는 AI를 정답률이 아니라 **현금흐름**으로 평가한다. 시작 자본 $10,
실시간 토큰 비용 차감, 작업 품질 기반 보수 지급 구조로 에이전트의 경제적
의사결정 능력을 벤치마킹한다.

## 핵심 구조

- **경제 압력**: 모든 호출에 비용이 붙고, 잔고가 0이면 종료
- **업무 환경**: GDPVal 공개 태스크 220개(44개 직종, 9개 산업)
- **보수 공식**: 품질 점수 × (인간 추정 작업시간 × BLS 시급)
- **실행 루프**: 태스크 배정 → 수행 → GPT-5.2 평가 → 보수 지급

## 짧은 인사이트

1. **평가 패러다임 전환**
   "할 수 있는가"보다 "남는 장사인가"를 묻는다.

2. **전략 지능 측정**
   `decide_activity`(일 vs 학습) 선택은 다중무장 밴딧과 유사한
   탐험-활용(explore-exploit) 문제를 드러낸다.

3. **비용 최소화 ≠ 이익 최대화**
   토큰 절약으로 품질이 크게 떨어지면 총보수가 더 줄어 역손실이 난다.

4. **속도 시급의 착시**
   "시간당 $1,500"은 인간 기준 작업시간을 AI가 압축해 생기는
   속도 프리미엄 성격이 강하다.

5. **평가 폐쇄 루프 리스크**
   LLM이 LLM을 채점하면 형식/길이 편향이 누적될 수 있어,
   인간 평가와의 교차 검증이 중요하다.

## 한계와 활용 포인트

- 협업, 맥락 전환, 감정 노동 같은 "실제 동료 역량"은 제한적으로 반영된다.
- 그럼에도 프로덕션 관점에서 "예산 기반 에이전트 운영" 설계에 유용하다.
- 특히 비용·품질·수익을 하나의 관측 지표(잔고)로 묶는 점이 실무적이다.

## 실무 적용 체크리스트

- 에이전트별 월/주 예산 상한을 둔다.
- 호출 단위 비용 추적과 태스크 단위 품질 점수를 함께 저장한다.
- "토큰/비용"이 아니라 "순이익(보상-비용)"을 1차 KPI로 둔다.
- 저품질 반복 영역은 자동 차단 규칙(쿨다운, 라우팅 변경)을 건다.

