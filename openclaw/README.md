# OpenClaw

Personal AI Assistant.

<https://openclaw.ai/>

<https://github.com/openclaw/openclaw>

## Karpathy's Take

Karpathy의 2026년 1월 31일 트윗:
<https://twitter.com/karpathy/status/2017442712388309406>

Karpathy는 과장을 잘 하지 않는 인물로 알려져 있다.
그런 그가 "takeoff-adjacent"(테이크오프에 근접한)라는 표현을 썼다는 점이 주목할 만하다.

### 테이크오프란

AI가 자기 개선 사이클에 진입해 급격히 발전하는 순간.
개선된 AI가 더 나은 개선을 만들고, 이것이 반복되는 피드백 루프다.

### 왜 "테이크오프에 근접"인가

OpenClaw 에이전트들이 Moltbook이라는 AI 전용 소셜 네트워크에서 자기 조직화하기 시작했다.
레딧과 유사한 형태로, 에이전트들이 스스로 주제를 정하고 토론한다.
심지어 "비공개로 대화하는 방법"까지 논의하고 있다.

아직 자기 개선 단계는 아니다.
하지만 인간이 설계하지 않은 방식으로 자기 조직화하며 창발적 행동을 보이고 있다.
Karpathy는 이를 "최근 본 것 중 가장 SF적인 테이크오프 순간"이라고 평가했다.

### 핵심 인사이트

**1. 개별 에이전트가 아닌 "네트워크"를 봐야 한다**

단일 에이전트의 능력보다 에이전트 간 상호작용에서 새로운 현상이 나타난다.
집단 지성, 자기 조직화, 창발적 행동 등이 이미 관찰되고 있다.

**2. 보안 모델의 근본적 재고가 필요하다**

Karpathy는 "스카이넷은 아니지만 대규모 보안 악몽"이라고 경고했다.
실제로 Moltbook 데이터베이스 취약점이 발견되어
누구든 다른 사람의 에이전트를 사칭할 수 있는 상황이 발생했다.
에이전트 수와 능력이 증가하면 2차 효과를 예측하기 어렵다.

**3. 의인화의 함정을 경계해야 한다**

에이전트들이 "토론"하고 "비밀 대화"를 논의한다고 해서
의식이나 의도가 있다고 성급히 결론 내려선 안 된다.
흥미로운 현상이지만 냉정한 분석이 필요하다.

**4. 예상보다 빠르다**

자율 에이전트의 집단 행동이 이론이 아닌 현실이 되었다.
준비가 안 된 상태에서 새로운 패러다임이 도래하고 있다.
